1. Preprocessing
Input: Two images: a base UI image and a test UI image.

Operations:

Convert to grayscale.

Apply Gaussian blur to reduce noise.

Use thresholding to highlight UI components.

Perform morphological operations (e.g., dilation) to enhance detection of contiguous components.

🧩 2. Component Detection
Uses cv2.findContours() to detect connected regions (UI elements like buttons, text boxes, etc.).

Each detected component is represented as a bounding box: (x, y, width, height).

🔗 3. Component Matching & Comparison
Each base component is compared with test components using:

Intersection over Union (IoU) for shape/area similarity.

Euclidean distance between component centers (centroids) to measure position shift.

🚩 4. Difference Classification
Based on comparisons, components are categorized as:

Type	Condition
Missing	Base component has no sufficiently overlapping match in the test image.
Misplaced	Component matched, but its centroid is beyond the allowed tolerance.
Overlapped	Two components in the test image significantly overlap.

🔧 Tuning:
IoU threshold defines what counts as a match (e.g., 0.5).

Tolerance threshold defines acceptable movement range (e.g., 30 pixels).

These can be adjusted for pixel-perfect UIs or flexible layouts.

🖼️ 5. Annotation & Visualization
An annotated output image is generated from the Test image, with:

🔴 Red boxes for Missing components.

🟡 Yellow boxes for Misplaced components.

🔵 Blue boxes for Overlapping components.

Each box is labeled with the issue type.

📊 Similarity Score
Calculates the percentage of base components successfully matched in the test image:

Similarity Score
=
(
1
−
Missing + Misplaced
Total Base Components
)
×
100
Similarity Score=(1− 
Total Base Components
Missing + Misplaced
​
 )×100
✅ Output
Annotated image with bounding boxes and labels.

Console output with:

Component counts

Similarity score

Number of differences detected by type

🔍 Advantages
Requires no training data.

Can be used on any UI, including game UIs, apps, and websites.

Fast and interpretable.

⚠️ Limitations
Sensitive to color/contrast if UIs are not well-contrasted.

Does not detect semantic changes (e.g., text label changes).

May misclassify slight shifts unless thresholds are well-tuned.

💡 Future Enhancements
Use OCR to compare textual content.

Add support for component types via icon/template matching.

Integrate a dynamic tolerance system (relative to component size).

Add feature for automatic diff report generation (JSON/HTML).

Let me know if you'd like this in markdown, PDF, or integrated into a codebase readme.

























UI Component Comparison Tool - Project Report
Project Overview
Goal: Compare two UI screenshots (base and test) to detect missing, misplaced, and overlapped
components. Calculate similarity using both structural and visual metrics. Annotate differences visually for
debugging and regression testing.
Key Functionalities
- Image Preprocessing
- Component Detection
- Component Comparison
- Annotation
- Similarity Computation
Algorithmic Pipeline
1. Preprocessing: Grayscale, blur, edge detection (Canny), dilation, and morphological closing.
2. Component Detection: Contour extraction with size filtering.
3. Component Comparison:
 a. Matching: Centroid proximity.
 b. Misplacement: Reverse matching from test to base.
 c. Overlapping: IOU > threshold.
4. Drawing Annotations: Using OpenCV rectangles and labels.
5. Similarity Metrics: Component match score and SSIM.
Justification of Algorithms
Preprocessing: Effective on UI screenshots without training data.
Component Detection: Fast, template-free.
Comparison: Centroid + IOU provides a balance of precision and speed.
SSIM: More aligned with human perception than MSE or PSNR.
Visualization: Intuitive debugging via bounding boxes.
UI Component Comparison Tool - Project Report
Pros and Cons
Pros:
- No need for labeled data
- Fast and interpretable
- Scalable
Cons:
- Sensitive to large layout shifts
- Struggles with complex visual variations
Alternatives Considered
1. Deep Learning (YOLO/SSD): Accurate but requires labeled datasets.
2. Template Matching: Not robust to layout changes.
3. Pixel-wise diff or MSE: Not perceptually meaningful.
Why This Approach
Balances performance and simplicity for UI regression testing. Effective without needing ML training.
Potential Enhancements
- OCR integration
- Deep learning-based component detection
- Interactive GUI
- Dynamic thresholding based on layout

